{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1BnZylT19zYKzr5NCaaFurOOlpo-V6u4c","timestamp":1714309146421},{"file_id":"1YZigrOxmjSMRcWg2FI8dV_PwKfSjAd3o","timestamp":1714309124887}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"code","metadata":{"id":"9JutkdoS4X-A","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"4bd9aa13-34ee-4a0a-8f6a-7eaaf6c7db84"},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","tf.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.15.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"r8vMWSpBX3iX"},"source":["# Softmax classification\n","\n","* 임의의 Dataset 준비\n","* 3개의 클래스로 분류할 데이터 준비\n"]},{"cell_type":"code","metadata":{"id":"lZH1QvjlFBsE"},"source":["x_data = [[1., 2., 1., 1.],\n","          [2., 1., 3., 2.],\n","          [3., 1., 3., 4.],\n","          [4., 1., 5., 5.],\n","          [1., 7., 5., 5.],\n","          [1., 2., 5., 6.],\n","          [1., 6., 6., 6.],\n","          [1., 7., 7., 7.]] # 8x4\n","y_data = [[0., 0., 1.],\n","          [0., 0., 1.],\n","          [0., 0., 1.],\n","          [0., 1., 0.],\n","          [0., 1., 0.],\n","          [0., 1., 0.],\n","          [1., 0., 0.],\n","          [1., 0., 0.]] # 8x3\n","\n","x_test = [[1., 1., 1., 1.]]\n","y_test = [[0., 0., 1.]]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qCPXA2luyvlN"},"source":["## 임의의 Data를 이용해서 3개의 클래스를 가지는 데이터셋 생성"]},{"cell_type":"code","metadata":{"id":"HpNjJzwwX7uz","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6965b792-dd22-41d4-e86a-0024df0782dc"},"source":["#dataset을 선언합니다.\n","dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\n","dataset = dataset.repeat(1).batch(8)\n","\n","nb_classes = 3 # class의 개수입니다.\n","\n","print(tf.Variable(x_data))\n","print(tf.Variable(y_data))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<tf.Variable 'Variable:0' shape=(8, 4) dtype=float32, numpy=\n","array([[1., 2., 1., 1.],\n","       [2., 1., 3., 2.],\n","       [3., 1., 3., 4.],\n","       [4., 1., 5., 5.],\n","       [1., 7., 5., 5.],\n","       [1., 2., 5., 6.],\n","       [1., 6., 6., 6.],\n","       [1., 7., 7., 7.]], dtype=float32)>\n","<tf.Variable 'Variable:0' shape=(8, 3) dtype=float32, numpy=\n","array([[0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.]], dtype=float32)>\n"]}]},{"cell_type":"code","metadata":{"id":"wmHTiEKcX_zD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"03b63dee-b6da-477e-8c9f-068b501f0219"},"source":["#Weight and bias setting\n","W = tf.Variable(tf.random.normal([4, nb_classes]), name='weight')\n","b = tf.Variable(tf.random.normal([nb_classes]), name='bias')\n","variables = [W, b]\n","\n","tf.print(W,b)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.781559408 0.213658348 0.562138617]\n"," [-1.23078358 -0.256780028 0.584250093]\n"," [-2.12305093 0.0466100127 -0.740654945]\n"," [1.42141116 1.5697372 -0.903915167]] [1.14577115 0.240724072 -0.71792388]\n"]}]},{"cell_type":"markdown","metadata":{"id":"4op7dp4RyvlT"},"source":["# 가설 설정\n","\n","* 가설에서 예측한 값들을 이용해 예측값들을 확률로 표현한다.\n","\n","## $$ y_k = \\frac{exp(x_k)}{\\sum_{i=1}^{n}exp(x_i)}  $$"]},{"cell_type":"code","metadata":{"id":"Kje8MUl-DOMO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0f12c0cc-38f1-4914-a1ac-c928f7a88a8d"},"source":["# tf.nn.softmax computes softmax activations\n","# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n","def hypothesis_softmax(X):\n","    return tf.nn.softmax(tf.matmul(X, W) + b)\n","\n","tf.print(hypothesis_softmax(tf.Variable(x_data)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0114036966 0.889004707 0.0995916]\n"," [0.000141054858 0.99866569 0.00119322923]\n"," [3.88055378e-05 0.999949038 1.20236891e-05]\n"," ...\n"," [1.03984314e-06 0.999998868 2.04282387e-08]\n"," [2.41367903e-09 0.999999702 2.68748153e-07]\n"," [8.97400626e-11 0.99999994 2.39002347e-08]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"aYnGTBv2S-DS"},"source":["## 가설을 검증할 Cross Entropy 함수를 정의합니다\n","\n","$$\n","\\begin{align}\n","cost(h(x),y) & = −\\sum_{n=1}^{n} Y log(h(x))\n","\\end{align}\n","$$"]},{"cell_type":"code","metadata":{"id":"fxXa5whUIwSN"},"source":["def loss_fn(hypothesis, labels):\n","    loss = tf.keras.losses.categorical_crossentropy(labels, hypothesis)\n","    # tf.keras.losses.binary_crossentropy(labels, hypothesis) # 이진분류용 CE Loss\n","    return loss\n","\n","optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k-3BTbBLyvla"},"source":["### 학습 진행"]},{"cell_type":"code","metadata":{"id":"hOHOKhWyIzk9","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b0a3e01d-1a9c-4181-d575-fd9ab7ece9da"},"source":["epochs = 5000\n","\n","for step in range(epochs):\n","  for features, labels in dataset:\n","    with tf.GradientTape() as tape:\n","      loss_value = loss_fn(hypothesis_softmax(features),labels)\n","      grads = tape.gradient(loss_value, [W,b])\n","      optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n","      if step % 100 == 0:\n","            print(\"Iter: {}, Loss: {:.4f}\".format(step, tf.reduce_mean(loss_value.numpy()).numpy()))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iter: 0, Loss: 6.5753\n","Iter: 100, Loss: 0.6299\n","Iter: 200, Loss: 0.5568\n","Iter: 300, Loss: 0.5079\n","Iter: 400, Loss: 0.4675\n","Iter: 500, Loss: 0.4322\n","Iter: 600, Loss: 0.4029\n","Iter: 700, Loss: 0.3790\n","Iter: 800, Loss: 0.3577\n","Iter: 900, Loss: 0.3384\n","Iter: 1000, Loss: 0.3210\n","Iter: 1100, Loss: 0.3052\n","Iter: 1200, Loss: 0.2907\n","Iter: 1300, Loss: 0.2774\n","Iter: 1400, Loss: 0.2652\n","Iter: 1500, Loss: 0.2539\n","Iter: 1600, Loss: 0.2435\n","Iter: 1700, Loss: 0.2339\n","Iter: 1800, Loss: 0.2249\n","Iter: 1900, Loss: 0.2165\n","Iter: 2000, Loss: 0.2087\n","Iter: 2100, Loss: 0.2015\n","Iter: 2200, Loss: 0.1946\n","Iter: 2300, Loss: 0.1882\n","Iter: 2400, Loss: 0.1822\n","Iter: 2500, Loss: 0.1766\n","Iter: 2600, Loss: 0.1712\n","Iter: 2700, Loss: 0.1662\n","Iter: 2800, Loss: 0.1614\n","Iter: 2900, Loss: 0.1569\n","Iter: 3000, Loss: 0.1526\n","Iter: 3100, Loss: 0.1486\n","Iter: 3200, Loss: 0.1447\n","Iter: 3300, Loss: 0.1410\n","Iter: 3400, Loss: 0.1375\n","Iter: 3500, Loss: 0.1342\n","Iter: 3600, Loss: 0.1310\n","Iter: 3700, Loss: 0.1280\n","Iter: 3800, Loss: 0.1251\n","Iter: 3900, Loss: 0.1223\n","Iter: 4000, Loss: 0.1196\n","Iter: 4100, Loss: 0.1171\n","Iter: 4200, Loss: 0.1146\n","Iter: 4300, Loss: 0.1122\n","Iter: 4400, Loss: 0.1100\n","Iter: 4500, Loss: 0.1078\n","Iter: 4600, Loss: 0.1057\n","Iter: 4700, Loss: 0.1037\n","Iter: 4800, Loss: 0.1018\n","Iter: 4900, Loss: 0.0999\n"]}]},{"cell_type":"markdown","metadata":{"id":"D6iMuYpxyvld"},"source":["## Sample 데이터를 넣고 테스트해봅시다."]},{"cell_type":"code","metadata":{"id":"pyNxH16II0st","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7e0f3ada-7e28-41ad-dcf9-3698f509e1b6"},"source":["sample_data = [[2,1,3,2]] # answer_label [[0,0,1]]\n","sample_data = np.asarray(sample_data, dtype=np.float32)\n","\n","a = hypothesis_softmax(sample_data)\n","\n","print(a)\n","print(tf.argmax(a, 1)) #index: 2"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([[1.8219676e-04 4.9082153e-02 9.5073569e-01]], shape=(1, 3), dtype=float32)\n","tf.Tensor([2], shape=(1,), dtype=int64)\n"]}]},{"cell_type":"markdown","metadata":{"id":"5rB-aJf0yvlg"},"source":["## 데이터를 이용해서 예측"]},{"cell_type":"code","metadata":{"id":"9qJfHxEnI25d","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2f871456-5719-42b8-a018-b657a811b980"},"source":["b = hypothesis_softmax(x_test)\n","print(b)\n","print(tf.argmax(b, 1))\n","print(tf.argmax(y_test, 1)) # matches with y_data\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([[3.459829e-07 5.923435e-04 9.994073e-01]], shape=(1, 3), dtype=float32)\n","tf.Tensor([2], shape=(1,), dtype=int64)\n","tf.Tensor([2], shape=(1,), dtype=int64)\n"]}]},{"cell_type":"code","metadata":{"id":"CkhpaF-rCMnZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e526ab6a-3c0d-4b04-f294-24d7ab609a88"},"source":["def accuracy_fn(hypothesis, labels):\n","    hypothesis = tf.argmax(hypothesis)\n","    hypothesis = tf.cast(hypothesis, dtype=tf.float32)\n","    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n","    labels = tf.argmax(labels)\n","    labels = tf.cast(labels, dtype=tf.float32)\n","    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float32))\n","    return accuracy\n","\n","test_acc = accuracy_fn(hypothesis_softmax(x_test),y_test)\n","print(\"Testset Accuracy: {:.4f}\".format(test_acc))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testset Accuracy: 1.0000\n"]}]},{"cell_type":"code","metadata":{"id":"CHq7WwDzE1oh"},"source":[],"execution_count":null,"outputs":[]}]}